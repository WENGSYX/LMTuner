# Lingo: Make the LLM Better for EveryoneðŸš€ðŸš€

Welcome to the Lingo Project - a grand stage for serving humanity with large-scale language models! ðŸŽ‰ðŸŽ‰

The core mission of Lingo is to harness the magical powers of large language models in more domains through a low-cost
approach. We believe that with just a little guidance and fine-tuning, these massive language models can demonstrate
jaw-dropping performance. ðŸ’«ðŸŒˆ

In the Lingo Project, we offer ultra-high-quality open-source data, efficient fine-tuning code, and fine-tuned model
weights. We are committed to providing you with the most comprehensive and effective tools and resources! ðŸš€ðŸš…

### ðŸ”„ Recent updates

* [2023/06/20] Release [Lingo-dataset-v1](https://huggingface.co/datasets/WENGSYX/Lingo-dataset-v1) On the basis of the
  LIMA dataset, we manually translated it into Chinese Q&A and adapted it in multiple places to adapt to the Chinese
  environment. Additionally, we added 100 high-quality Chinese dialogue corpora that we have written.

### How to install

```
git clone https://github.com/WENGSYX/lingo
pip install .
```

### Create your characteristic dataset

```python
from lingo.dataset import LingoDataset

dataset = LingoDataset()
# Give your model a name
dataset.set_model_name('Cognitive Intelligence Model')
# Add QA dataset samples
dataset.add_sample(['Who are you?',
                    "Hello everyone! I am a great artificial intelligence assistant, a cognitive intelligence model, created by the Language and Knowledge Computing Research Group of the Institute of Automation, Chinese Academy of Sciences. I am like your personal assistant, able to chat with you in fluent natural language. Whether it's answering questions or providing assistance, I can easily handle it. Although I don't have a physical image, I will do my best to provide you with the most thoughtful service"])
```

We have manually translated the LIMA dataset into Chinese Q&A, and rewrote it in many places to adapt to the Chinese
environment. In addition, we have added 100 high-quality Chinese dialogue materials written by us.

- We have built-in dozens of samples with model names, and by simply calling `lingo_dataset.set_model_name`, you can
  update the model name for all samples with one click.
- We support adding new samples. Call `lingo_dataset.add_sample` and pass in a dialogue list to automatically add new
  dialogue samples.
- Get the dataset with one click. Calling `lingo_dataset.get_list()` will return a list-format dataset, and you can
  continue to train new models on this basis.

### ðŸŒ± Lingo's Roadmap ðŸŒ±

Version-1:

- [x] Release Lingo Dataset
- [ ] Release Lingo Code for finetune
- [ ] Release LLM Weight

Version-2:

- [ ] Add "Function Calling" in dataset-v2
- [ ] ...

### Cite

This project is an accompanying project of [Neural Comprehension](https://github.com/WENGSYX/Neural-Comprehension). If you are interested in our project, please feel free
to quote.

```
@misc{weng2023mastering,
      title={Mastering Symbolic Operations: Augmenting Language Models with Compiled Neural Networks}, 
      author={Yixuan Weng and Minjun Zhu and Fei Xia and Bin Li and Shizhu He and Kang Liu and Jun Zhao},
      year={2023},
      eprint={2304.01665},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

### Disclaimers

**The resources related to this project are for academic research purposes only and are strictly prohibited from
commercial use** When using parts involving third-party code, please strictly follow the corresponding open source
protocol. The content generated by the model is affected by factors such as model calculation, randomness, and loss of
quantification accuracy. This project does not guarantee its accuracy. For any content output by the model, this project
does not assume any legal responsibility, nor is it liable for any losses that may arise from the use of relevant
resources and output results
